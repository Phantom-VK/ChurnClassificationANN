{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed71ea69-8951-43e1-918e-5cbb579c13a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e11040e7-5758-4c9a-9eff-e957354f9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Churn_Modelling.csv')\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "label_encoder_gender = LabelEncoder()\n",
    "data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])\n",
    "\n",
    "onehot_encoder_geo = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "geo_encoded = onehot_encoder_geo.fit_transform(data[['Geography']])\n",
    "geo_encoded_df = pd.DataFrame(geo_encoded, columns=onehot_encoder_geo.get_feature_names_out(['Geography']))\n",
    "\n",
    "data = pd.concat([data.drop('Geography', axis=1), geo_encoded_df], axis=1)\n",
    "\n",
    "X = data.drop('Exited', axis=1)\n",
    "y = data['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save encoders and scaler for later use\n",
    "with open('label_encoder_gender.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoder_gender, file)\n",
    "\n",
    "with open('onehot_encoder_geo.pkl', 'wb') as file:\n",
    "    pickle.dump(onehot_encoder_geo, file)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e7e42fe-bbde-4e69-b9a9-2970fe249987",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function to create the model and try different parameters(KerasClassifier)\n",
    "\n",
    "def create_model(neurons=32,layers=1):\n",
    "    model=Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],)), Dense(neurons,activation='relu'))\n",
    "\n",
    "    for _ in range(layers-1):\n",
    "        model.add(Dense(neurons,activation='relu'))\n",
    "\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf63e047-9e54-4ded-8bfd-3649d25c6417",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a Keras classifier\n",
    "model=KerasClassifier(layers=1,neurons=32,build_fn=create_model,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d05108a6-003f-4e28-8cda-843ebb94cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the grid search parameters\n",
    "param_grid = {\n",
    "    'neurons': [16, 32, 64, 128],\n",
    "    'layers': [1, 2],\n",
    "    'epochs': [50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d8fdddc-51c3-4163-a2db-c435fdf50587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:29:39.090255: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-25 22:29:39.108800: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753462779.129587   28017 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753462779.135619   28017 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753462779.151121   28017 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.151321   28017 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.151360   28017 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.151386   28017 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-25 22:29:39.155652: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-25 22:29:39.159943: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-25 22:29:39.166711: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-25 22:29:39.172018: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-25 22:29:39.173477: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-25 22:29:39.186154: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-25 22:29:39.193712: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753462779.201268   28018 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753462779.205437   28008 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753462779.206818   28018 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "E0000 00:00:1753462779.211488   28008 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753462779.214120   28010 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753462779.220621   28010 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753462779.222897   28018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.223071   28018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.223099   28018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.223117   28018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-25 22:29:39.227647: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "W0000 00:00:1753462779.227744   28008 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.227778   28008 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.227780   28008 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.227782   28008 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-25 22:29:39.232499: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "W0000 00:00:1753462779.238504   28010 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.238692   28010 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.238728   28010 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.238749   28010 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-25 22:29:39.243384: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-25 22:29:39.246655: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-25 22:29:39.255122: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-25 22:29:39.265717: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-25 22:29:39.266961: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-25 22:29:39.274941: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-25 22:29:39.285710: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753462779.287124   28011 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753462779.293200   28011 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753462779.297288   28012 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753462779.303430   28012 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753462779.308423   28013 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "W0000 00:00:1753462779.310026   28011 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.310223   28011 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.310276   28011 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.310316   28011 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-25 22:29:39.314846: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "E0000 00:00:1753462779.315162   28013 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753462779.320210   28012 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.320372   28012 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.320411   28012 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.320437   28012 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-25 22:29:39.325578: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-25 22:29:39.325633: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "W0000 00:00:1753462779.332434   28013 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.332731   28013 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.332837   28013 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.332925   28013 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-25 22:29:39.337452: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-25 22:29:39.340527: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-25 22:29:39.349336: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-25 22:29:39.351108: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-25 22:29:39.352969: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-25 22:29:39.361705: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753462779.371410   28016 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-25 22:29:39.375605: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "E0000 00:00:1753462779.379265   28016 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753462779.383713   28015 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-25 22:29:39.389904: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "E0000 00:00:1753462779.390276   28015 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753462779.401273   28016 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.401502   28016 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.401571   28016 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.401640   28016 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753462779.406027   28019 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "W0000 00:00:1753462779.407129   28015 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.407254   28015 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.407297   28015 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.407401   28015 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-25 22:29:39.408871: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-25 22:29:39.412074: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "E0000 00:00:1753462779.414414   28019 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753462779.427568   28014 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753462779.436651   28014 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753462779.440250   28019 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.440424   28019 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.440490   28019 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.440534   28019 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-25 22:29:39.446845: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-25 22:29:39.464004: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "W0000 00:00:1753462779.468595   28014 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.468759   28014 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.468815   28014 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.468819   28014 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-25 22:29:39.477324: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-25 22:29:39.489711: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753462779.523018   28009 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753462779.530123   28009 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753462779.549527   28009 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.549706   28009 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.549761   28009 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753462779.549802   28009 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-25 22:29:39.555326: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "I0000 00:00:1753462783.559803   28008 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2430 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "I0000 00:00:1753462783.661472   28017 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2430 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "I0000 00:00:1753462783.670865   28012 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2396 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "I0000 00:00:1753462783.680357   28017 cuda_executor.cc:479] failed to allocate 2.37GiB (2548891648 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.691342   28017 cuda_executor.cc:479] failed to allocate 2.14GiB (2294002432 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.693942   28012 cuda_executor.cc:479] failed to allocate 2.34GiB (2513240064 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.707659   28017 cuda_executor.cc:479] failed to allocate 1.92GiB (2064602112 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.707751   28012 cuda_executor.cc:479] failed to allocate 2.11GiB (2261915904 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.712315   28017 cuda_executor.cc:479] failed to allocate 1.73GiB (1858141952 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.713167   28017 cuda_executor.cc:479] failed to allocate 1.56GiB (1672327680 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.713181   28012 cuda_executor.cc:479] failed to allocate 1.90GiB (2035724288 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.713237   28017 cuda_executor.cc:479] failed to allocate 1.40GiB (1505094912 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.713362   28017 cuda_executor.cc:479] failed to allocate 1.26GiB (1354585344 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.714527   28012 cuda_executor.cc:479] failed to allocate 1.71GiB (1832151808 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.714764   28017 cuda_executor.cc:479] failed to allocate 1.13GiB (1219126784 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.714849   28017 cuda_executor.cc:479] failed to allocate 1.02GiB (1097214208 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.714848   28012 cuda_executor.cc:479] failed to allocate 1.54GiB (1648936704 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.717572   28012 cuda_executor.cc:479] failed to allocate 1.38GiB (1484043008 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.717984   28012 cuda_executor.cc:479] failed to allocate 1.24GiB (1335638784 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.721851   28012 cuda_executor.cc:479] failed to allocate 1.12GiB (1202074880 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.722255   28012 cuda_executor.cc:479] failed to allocate 1.01GiB (1081867520 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.722314   28012 cuda_executor.cc:479] failed to allocate 928.57MiB (973680896 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.725099   28012 cuda_executor.cc:479] failed to allocate 835.72MiB (876312832 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.725467   28018 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2374 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "I0000 00:00:1753462783.726506   28012 cuda_executor.cc:479] failed to allocate 752.15MiB (788681728 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.728072   28012 cuda_executor.cc:479] failed to allocate 676.93MiB (709813760 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.728152   28012 cuda_executor.cc:479] failed to allocate 609.24MiB (638832384 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.731159   28012 cuda_executor.cc:479] failed to allocate 548.31MiB (574949120 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.739203   28012 cuda_executor.cc:479] failed to allocate 493.48MiB (517454336 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.768747   28012 cuda_executor.cc:479] failed to allocate 444.13MiB (465709056 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.768782   28018 cuda_executor.cc:479] failed to allocate 2.32GiB (2490171392 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.782901   28018 cuda_executor.cc:479] failed to allocate 2.09GiB (2241154304 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.783068   28012 cuda_executor.cc:479] failed to allocate 399.72MiB (419138304 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.784135   28018 cuda_executor.cc:479] failed to allocate 1.88GiB (2017038848 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.784197   28012 cuda_executor.cc:479] failed to allocate 359.75MiB (377224448 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.784815   28018 cuda_executor.cc:479] failed to allocate 1.69GiB (1815334912 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.785611   28018 cuda_executor.cc:479] failed to allocate 1.52GiB (1633801472 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.786243   28018 cuda_executor.cc:479] failed to allocate 1.37GiB (1470421248 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.790077   28018 cuda_executor.cc:479] failed to allocate 1.23GiB (1323379200 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.790464   28012 cuda_executor.cc:479] failed to allocate 323.77MiB (339502080 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.798133   28012 cuda_executor.cc:479] failed to allocate 291.40MiB (305551872 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.799603   28018 cuda_executor.cc:479] failed to allocate 1.11GiB (1191041280 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.799840   28012 cuda_executor.cc:479] failed to allocate 262.26MiB (274996736 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.801368   28018 cuda_executor.cc:479] failed to allocate 1022.28MiB (1071937280 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.802656   28018 cuda_executor.cc:479] failed to allocate 920.05MiB (964743680 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.802667   28012 cuda_executor.cc:479] failed to allocate 236.03MiB (247497216 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.807446   28018 cuda_executor.cc:479] failed to allocate 828.05MiB (868269312 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.807838   28012 cuda_executor.cc:479] failed to allocate 212.43MiB (222747648 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.818517   28018 cuda_executor.cc:479] failed to allocate 745.24MiB (781442560 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.819700   28018 cuda_executor.cc:479] failed to allocate 670.72MiB (703298304 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.820220   28018 cuda_executor.cc:479] failed to allocate 603.65MiB (632968448 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.820250   28012 cuda_executor.cc:479] failed to allocate 191.19MiB (200473088 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.821387   28018 cuda_executor.cc:479] failed to allocate 543.28MiB (569671680 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.825226   28012 cuda_executor.cc:479] failed to allocate 172.07MiB (180425984 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.833024   28018 cuda_executor.cc:479] failed to allocate 488.95MiB (512704512 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.834742   28012 cuda_executor.cc:479] failed to allocate 154.86MiB (162383616 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.838283   28018 cuda_executor.cc:479] failed to allocate 440.06MiB (461434112 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.838423   28018 cuda_executor.cc:479] failed to allocate 396.05MiB (415290880 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.846610   28012 cuda_executor.cc:479] failed to allocate 139.38MiB (146145280 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.850066   28018 cuda_executor.cc:479] failed to allocate 356.45MiB (373761792 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.850448   28018 cuda_executor.cc:479] failed to allocate 320.80MiB (336385792 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.850844   28018 cuda_executor.cc:479] failed to allocate 288.72MiB (302747392 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.852628   28018 cuda_executor.cc:479] failed to allocate 259.85MiB (272472832 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.852660   28012 cuda_executor.cc:479] failed to allocate 125.44MiB (131530752 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.852927   28018 cuda_executor.cc:479] failed to allocate 233.87MiB (245225728 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.856045   28012 cuda_executor.cc:479] failed to allocate 112.89MiB (118377728 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.856312   28018 cuda_executor.cc:479] failed to allocate 210.48MiB (220703232 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.856340   28012 cuda_executor.cc:479] failed to allocate 101.60MiB (106540032 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.884950   28018 cuda_executor.cc:479] failed to allocate 189.43MiB (198632960 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.884950   28012 cuda_executor.cc:479] failed to allocate 91.44MiB (95886080 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.891176   28012 cuda_executor.cc:479] failed to allocate 82.30MiB (86297600 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.897813   28012 cuda_executor.cc:479] failed to allocate 74.07MiB (77667840 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.901492   28018 cuda_executor.cc:479] failed to allocate 170.49MiB (178769664 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.914832   28012 cuda_executor.cc:479] failed to allocate 66.66MiB (69901056 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.935142   28018 cuda_executor.cc:479] failed to allocate 153.44MiB (160892928 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.939817   28012 cuda_executor.cc:479] failed to allocate 60.00MiB (62910976 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.945877   28012 cuda_executor.cc:479] failed to allocate 54.00MiB (56620032 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.960848   28012 cuda_executor.cc:479] failed to allocate 48.60MiB (50958080 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.960840   28018 cuda_executor.cc:479] failed to allocate 138.10MiB (144803840 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.961467   28012 cuda_executor.cc:479] failed to allocate 43.74MiB (45862400 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.964165   28012 cuda_executor.cc:479] failed to allocate 39.36MiB (41276160 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.965983   28012 cuda_executor.cc:479] failed to allocate 35.43MiB (37148672 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.977472   28012 cuda_executor.cc:479] failed to allocate 31.88MiB (33433856 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.985800   28016 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "I0000 00:00:1753462783.986659   28018 cuda_executor.cc:479] failed to allocate 124.29MiB (130323456 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.995575   28018 cuda_executor.cc:479] failed to allocate 111.86MiB (117291264 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.996674   28012 cuda_executor.cc:479] failed to allocate 28.70MiB (30090496 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.996908   28012 cuda_executor.cc:479] failed to allocate 25.83MiB (27081472 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462783.998806   28018 cuda_executor.cc:479] failed to allocate 100.67MiB (105562368 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.012341   28018 cuda_executor.cc:479] failed to allocate 90.60MiB (95006208 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.012452   28018 cuda_executor.cc:479] failed to allocate 81.54MiB (85505792 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.012490   28018 cuda_executor.cc:479] failed to allocate 73.39MiB (76955392 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.012564   28018 cuda_executor.cc:479] failed to allocate 66.05MiB (69260032 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.012604   28018 cuda_executor.cc:479] failed to allocate 59.45MiB (62334208 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.012647   28018 cuda_executor.cc:479] failed to allocate 53.50MiB (56100864 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.012679   28018 cuda_executor.cc:479] failed to allocate 48.15MiB (50490880 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.012716   28018 cuda_executor.cc:479] failed to allocate 43.34MiB (45441792 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.012752   28018 cuda_executor.cc:479] failed to allocate 39.00MiB (40897792 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.012794   28018 cuda_executor.cc:479] failed to allocate 35.10MiB (36808192 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.012851   28018 cuda_executor.cc:479] failed to allocate 31.59MiB (33127424 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.012896   28018 cuda_executor.cc:479] failed to allocate 28.43MiB (29814784 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.012947   28018 cuda_executor.cc:479] failed to allocate 25.59MiB (26833408 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.012987   28018 cuda_executor.cc:479] failed to allocate 23.03MiB (24150272 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.013029   28018 cuda_executor.cc:479] failed to allocate 20.73MiB (21735424 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.013074   28018 cuda_executor.cc:479] failed to allocate 18.66MiB (19561984 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.013120   28018 cuda_executor.cc:479] failed to allocate 16.79MiB (17605888 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.013159   28018 cuda_executor.cc:479] failed to allocate 15.11MiB (15845376 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.013203   28018 cuda_executor.cc:479] failed to allocate 13.60MiB (14260992 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.013251   28018 cuda_executor.cc:479] failed to allocate 12.24MiB (12835072 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.013289   28018 cuda_executor.cc:479] failed to allocate 11.02MiB (11551744 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.013318   28018 cuda_executor.cc:479] failed to allocate 9.92MiB (10396672 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.013347   28018 cuda_executor.cc:479] failed to allocate 8.92MiB (9357056 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.013373   28018 cuda_executor.cc:479] failed to allocate 8.03MiB (8421376 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.031062   28012 cuda_executor.cc:479] failed to allocate 23.24MiB (24373504 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.031738   28016 cuda_executor.cc:479] failed to allocate 2.81MiB (2949120 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.031835   28016 cuda_executor.cc:479] failed to allocate 2.53MiB (2654208 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.031902   28016 cuda_executor.cc:479] failed to allocate 2.28MiB (2388992 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.031926   28016 cuda_executor.cc:479] failed to allocate 2.05MiB (2150144 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.031954   28016 cuda_executor.cc:479] failed to allocate 1.85MiB (1935360 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.031978   28016 cuda_executor.cc:479] failed to allocate 1.66MiB (1741824 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.032001   28016 cuda_executor.cc:479] failed to allocate 1.50MiB (1567744 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.032025   28016 cuda_executor.cc:479] failed to allocate 1.35MiB (1411072 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.032075   28016 cuda_executor.cc:479] failed to allocate 1.21MiB (1270016 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.032098   28016 cuda_executor.cc:479] failed to allocate 1.09MiB (1143040 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.032125   28016 cuda_executor.cc:479] failed to allocate 1004.8KiB (1028864 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.032748   28012 cuda_executor.cc:479] failed to allocate 20.92MiB (21936384 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.034508   28016 cuda_executor.cc:479] failed to allocate 904.5KiB (926208 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.034645   28012 cuda_executor.cc:479] failed to allocate 18.83MiB (19742976 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.035863   28012 cuda_executor.cc:479] failed to allocate 16.95MiB (17768704 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.036282   28012 cuda_executor.cc:479] failed to allocate 15.25MiB (15992064 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.037863   28012 cuda_executor.cc:479] failed to allocate 13.73MiB (14393088 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.039610   28012 cuda_executor.cc:479] failed to allocate 12.35MiB (12953856 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.040183   28012 cuda_executor.cc:479] failed to allocate 11.12MiB (11658496 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.040222   28012 cuda_executor.cc:479] failed to allocate 10.01MiB (10492672 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.040264   28012 cuda_executor.cc:479] failed to allocate 9.01MiB (9443584 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.041086   28012 cuda_executor.cc:479] failed to allocate 8.11MiB (8499456 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.042719   28012 cuda_executor.cc:479] failed to allocate 7.29MiB (7649536 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1753462784.045935   28012 cuda_executor.cc:479] failed to allocate 6.57MiB (6884608 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753462785.020289   28270 service.cc:152] XLA service 0x7f32a0017480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753462785.020314   28270 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "2025-07-25 22:29:45.038685: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753462785.150485   28282 service.cc:152] XLA service 0x7ce9ec0067d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753462785.150532   28282 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "2025-07-25 22:29:45.167291: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753462785.215008   28313 service.cc:152] XLA service 0x7b4128006db0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753462785.215035   28313 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2025-07-25 22:29:45.227207: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1753462785.319454   28270 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "E0000 00:00:1753462785.350023   28313 cuda_dnn.cc:534] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "E0000 00:00:1753462785.351443   28313 cuda_dnn.cc:538] Memory usage: 2949120 bytes free, 3896180736 bytes total.\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "E0000 00:00:1753462785.365617   28282 cuda_dnn.cc:534] Could not create cudnn handle: <unknown cudnn status: 4004>\n",
      "E0000 00:00:1753462785.370920   28282 cuda_dnn.cc:538] Memory usage: 5046272 bytes free, 3896180736 bytes total.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753462785.376936   28296 service.cc:152] XLA service 0x7092bc005770 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753462785.376950   28296 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2025-07-25 22:29:45.388199: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753462785.425772   28364 service.cc:152] XLA service 0x7c0f58005fa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753462785.425795   28364 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "2025-07-25 22:29:45.441573: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "E0000 00:00:1753462785.465349   28313 cuda_dnn.cc:534] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "E0000 00:00:1753462785.465421   28313 cuda_dnn.cc:538] Memory usage: 2949120 bytes free, 3896180736 bytes total.\n",
      "I0000 00:00:1753462785.465859   28282 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-07-25 22:29:45.467992: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at xla_ops.cc:591 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2025-07-25 22:29:45.468057: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n",
      "I0000 00:00:1753462785.492400   28270 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 55/167\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4247 - loss: 1.0714Epoch 1/100\n",
      "\u001b[1m 28/167\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5082 - loss: 0.9340 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "I0000 00:00:1753462785.582160   28296 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "I0000 00:00:1753462785.637055   28282 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1753462785.641850   28364 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/167\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:38\u001b[0m 952ms/step - accuracy: 0.4688 - loss: 1.2186.9184  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753462785.790264   28296 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "I0000 00:00:1753462785.846135   28364 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 88/167\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4550 - loss: 1.0689  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4508 - loss: 1.0142\n",
      "Epoch 2/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5154 - loss: 0.9059\n",
      "Epoch 2/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4607 - loss: 1.0457\n",
      "Epoch 2/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4753 - loss: 0.9590\n",
      "\u001b[1m 31/167\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5245 - loss: 0.8165 Epoch 2/50\n",
      "\u001b[1m 29/167\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5300 - loss: 0.8059 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753462786.581870   28312 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5052 - loss: 0.8583\n",
      "Epoch 3/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5336 - loss: 0.7877\n",
      "Epoch 3/50\n",
      "\u001b[1m 59/167\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5658 - loss: 0.7304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753462786.796941   28312 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5059 - loss: 0.8780\n",
      "\u001b[1m108/167\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4540 - loss: 0.9186Epoch 3/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5229 - loss: 0.8040\n",
      "Epoch 3/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5767 - loss: 0.7116\n",
      "Epoch 4/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6010 - loss: 0.6736\n",
      "Epoch 4/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5796 - loss: 0.7317\n",
      "Epoch 4/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5844 - loss: 0.6920\n",
      "Epoch 4/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4596 - loss: 0.9044 \n",
      "Epoch 2/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6577 - loss: 0.6337\n",
      "Epoch 5/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6636 - loss: 0.6054\n",
      "Epoch 5/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6712 - loss: 0.6247\n",
      "Epoch 5/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6566 - loss: 0.6256\n",
      "Epoch 5/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5435 - loss: 0.7533\n",
      "Epoch 3/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7420 - loss: 0.5660\n",
      "Epoch 6/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7562 - loss: 0.5436\n",
      "Epoch 6/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7385 - loss: 0.5637\n",
      "Epoch 6/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7213 - loss: 0.5690\n",
      "Epoch 6/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6359 - loss: 0.6479\n",
      "Epoch 4/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7901 - loss: 0.5262\n",
      "Epoch 7/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8061 - loss: 0.5126\n",
      "Epoch 7/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7733 - loss: 0.5277\n",
      "Epoch 7/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7755 - loss: 0.5294\n",
      "Epoch 7/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7276 - loss: 0.5842\n",
      "Epoch 5/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8006 - loss: 0.4985\n",
      "Epoch 8/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7946 - loss: 0.5023\n",
      "Epoch 8/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7876 - loss: 0.4997\n",
      "Epoch 8/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8056 - loss: 0.4949\n",
      "Epoch 8/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7809 - loss: 0.5384\n",
      "Epoch 6/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7897 - loss: 0.4906\n",
      "Epoch 9/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8013 - loss: 0.4830\n",
      "Epoch 9/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7956 - loss: 0.4837\n",
      "Epoch 9/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8013 - loss: 0.4847\n",
      "Epoch 9/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7973 - loss: 0.5050\n",
      "Epoch 7/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8042 - loss: 0.4658\n",
      "Epoch 10/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8138 - loss: 0.4639\n",
      "Epoch 10/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8102 - loss: 0.4647\n",
      "Epoch 10/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8085 - loss: 0.4634\n",
      "Epoch 10/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7979 - loss: 0.4935\n",
      "Epoch 8/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.4579\n",
      "Epoch 11/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8120 - loss: 0.4557\n",
      "Epoch 11/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8130 - loss: 0.4532\n",
      "Epoch 11/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8093 - loss: 0.4521\n",
      "Epoch 11/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7958 - loss: 0.4725\n",
      "Epoch 9/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8036 - loss: 0.4580\n",
      "Epoch 12/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.4553\n",
      "Epoch 12/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8084 - loss: 0.4444\n",
      "Epoch 12/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8142 - loss: 0.4473\n",
      "Epoch 12/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8121 - loss: 0.4498\n",
      "Epoch 10/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8050 - loss: 0.4509\n",
      "Epoch 13/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8114 - loss: 0.4448\n",
      "Epoch 13/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.4345\n",
      "Epoch 13/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8018 - loss: 0.4430\n",
      "Epoch 13/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8017 - loss: 0.4562\n",
      "Epoch 11/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8063 - loss: 0.4468\n",
      "Epoch 14/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8070 - loss: 0.4474\n",
      "Epoch 14/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8112 - loss: 0.4373\n",
      "Epoch 14/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8110 - loss: 0.4379\n",
      "Epoch 14/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8114 - loss: 0.4404\n",
      "Epoch 12/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8102 - loss: 0.4410\n",
      "Epoch 15/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8129 - loss: 0.4370\n",
      "Epoch 15/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8154 - loss: 0.4400\n",
      "Epoch 15/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.4391\n",
      "Epoch 15/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8088 - loss: 0.4404\n",
      "Epoch 13/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8084 - loss: 0.4413\n",
      "Epoch 16/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: 0.4490\n",
      "Epoch 16/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.4378\n",
      "Epoch 16/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8106 - loss: 0.4409\n",
      "Epoch 16/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8013 - loss: 0.4459\n",
      "Epoch 14/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8128 - loss: 0.4395\n",
      "Epoch 17/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8120 - loss: 0.4357\n",
      "Epoch 17/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8114 - loss: 0.4249\n",
      "Epoch 17/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8255 - loss: 0.4175\n",
      "Epoch 17/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8022 - loss: 0.4419\n",
      "Epoch 15/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8085 - loss: 0.4355\n",
      "Epoch 18/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8088 - loss: 0.4351\n",
      "Epoch 18/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8119 - loss: 0.4285\n",
      "Epoch 18/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8058 - loss: 0.4382\n",
      "Epoch 18/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8007 - loss: 0.4426\n",
      "Epoch 16/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8138 - loss: 0.4316\n",
      "Epoch 19/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8047 - loss: 0.4415\n",
      "Epoch 19/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8117 - loss: 0.4282\n",
      "Epoch 19/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8095 - loss: 0.4404\n",
      "Epoch 19/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8155 - loss: 0.4262\n",
      "Epoch 17/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8051 - loss: 0.4418\n",
      "Epoch 20/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8092 - loss: 0.4370\n",
      "Epoch 20/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.4177\n",
      "Epoch 20/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8145 - loss: 0.4283\n",
      "\u001b[1m 73/167\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8008 - loss: 0.4483Epoch 20/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8100 - loss: 0.4302\n",
      "Epoch 18/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8031 - loss: 0.4446\n",
      "Epoch 21/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7999 - loss: 0.4435\n",
      "Epoch 21/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8046 - loss: 0.4387\n",
      "Epoch 21/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8010 - loss: 0.4473\n",
      "Epoch 21/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7955 - loss: 0.4477\n",
      "Epoch 19/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8127 - loss: 0.4319\n",
      "Epoch 22/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8088 - loss: 0.4425 \n",
      "Epoch 22/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8088 - loss: 0.4328\n",
      "Epoch 22/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8137 - loss: 0.4308\n",
      "Epoch 22/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4254\n",
      "Epoch 20/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8112 - loss: 0.4317\n",
      "Epoch 23/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8038 - loss: 0.4413\n",
      "Epoch 23/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8233 - loss: 0.4110\n",
      "Epoch 23/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8182 - loss: 0.4184\n",
      "Epoch 23/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8026 - loss: 0.4365\n",
      "Epoch 21/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8041 - loss: 0.4411\n",
      "Epoch 24/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8085 - loss: 0.4425\n",
      "Epoch 24/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8107 - loss: 0.4344\n",
      "Epoch 24/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8128 - loss: 0.4287\n",
      "Epoch 24/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8074 - loss: 0.4364\n",
      "Epoch 22/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8201 - loss: 0.4297\n",
      "Epoch 25/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.4360\n",
      "Epoch 25/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8123 - loss: 0.4309\n",
      "Epoch 25/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8002 - loss: 0.4471\n",
      "Epoch 25/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8056 - loss: 0.4376\n",
      "Epoch 23/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8077 - loss: 0.4417\n",
      "Epoch 26/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8105 - loss: 0.4360\n",
      "Epoch 26/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8158 - loss: 0.4295\n",
      "Epoch 26/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8106 - loss: 0.4263\n",
      "\u001b[1m  1/167\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7812 - loss: 0.5686Epoch 26/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8113 - loss: 0.4263\n",
      "Epoch 24/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8066 - loss: 0.4381\n",
      "Epoch 27/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8032 - loss: 0.4457\n",
      "Epoch 27/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8160 - loss: 0.4280\n",
      "Epoch 27/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8123 - loss: 0.4286\n",
      "Epoch 27/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8041 - loss: 0.4380\n",
      "Epoch 25/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8138 - loss: 0.4272\n",
      "Epoch 28/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8170 - loss: 0.4248\n",
      "Epoch 28/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.4289\n",
      "Epoch 28/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8082 - loss: 0.4332\n",
      "Epoch 28/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8113 - loss: 0.4298\n",
      "Epoch 26/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8061 - loss: 0.4449\n",
      "Epoch 29/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8059 - loss: 0.4409\n",
      "Epoch 29/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.4231\n",
      "Epoch 29/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8144 - loss: 0.4262\n",
      "\u001b[1m 58/167\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8067 - loss: 0.4411Epoch 29/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8063 - loss: 0.4363\n",
      "Epoch 27/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8044 - loss: 0.4438\n",
      "Epoch 30/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8113 - loss: 0.4306\n",
      "Epoch 30/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8197 - loss: 0.4161\n",
      "Epoch 30/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8065 - loss: 0.4384\n",
      "Epoch 30/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8109 - loss: 0.4280\n",
      "Epoch 28/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8119 - loss: 0.4345\n",
      "Epoch 31/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8170 - loss: 0.4294\n",
      "Epoch 31/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8104 - loss: 0.4278\n",
      "Epoch 31/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8030 - loss: 0.4403\n",
      "Epoch 31/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8114 - loss: 0.4337\n",
      "Epoch 32/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8055 - loss: 0.4339\n",
      "\u001b[1m124/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8084 - loss: 0.4345Epoch 29/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8101 - loss: 0.4330\n",
      "Epoch 32/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8113 - loss: 0.4342\n",
      "Epoch 32/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8068 - loss: 0.4411\n",
      "Epoch 32/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8100 - loss: 0.4293\n",
      "Epoch 30/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.4322\n",
      "Epoch 33/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8159 - loss: 0.4255\n",
      "Epoch 33/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8021 - loss: 0.4450\n",
      "Epoch 33/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8091 - loss: 0.4430\n",
      "Epoch 33/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8125 - loss: 0.4296\n",
      "Epoch 34/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8092 - loss: 0.4282\n",
      "Epoch 31/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8088 - loss: 0.4337\n",
      "Epoch 34/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8101 - loss: 0.4318\n",
      "Epoch 34/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.4121\n",
      "Epoch 34/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8136 - loss: 0.4211\n",
      "Epoch 32/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8132 - loss: 0.4357\n",
      "Epoch 35/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8137 - loss: 0.4319\n",
      "Epoch 35/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8133 - loss: 0.4217\n",
      "Epoch 35/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8216 - loss: 0.4155\n",
      "Epoch 35/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8126 - loss: 0.4253\n",
      "\u001b[1m120/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8041 - loss: 0.4376Epoch 33/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8234 - loss: 0.4159\n",
      "Epoch 36/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.4201\n",
      "Epoch 36/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8062 - loss: 0.4357\n",
      "Epoch 36/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.4241\n",
      "Epoch 36/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8102 - loss: 0.4381\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8046 - loss: 0.4413\n",
      "Epoch 34/100\n",
      "Epoch 37/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.4338\n",
      "Epoch 37/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8102 - loss: 0.4405\n",
      "Epoch 37/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8139 - loss: 0.4228\n",
      "Epoch 37/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8162 - loss: 0.4283\n",
      "Epoch 35/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8153 - loss: 0.4273\n",
      "Epoch 38/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8201 - loss: 0.4240\n",
      "\u001b[1m 29/167\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8044 - loss: 0.4537 Epoch 38/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8208 - loss: 0.4245\n",
      "Epoch 38/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8102 - loss: 0.4320\n",
      "Epoch 38/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8112 - loss: 0.4273\n",
      "Epoch 36/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8116 - loss: 0.4376\n",
      "Epoch 39/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8092 - loss: 0.4322\n",
      "Epoch 39/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8158 - loss: 0.4266\n",
      "Epoch 39/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.4352\n",
      "Epoch 39/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8067 - loss: 0.4346\n",
      "Epoch 37/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8083 - loss: 0.4366\n",
      "Epoch 40/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8048 - loss: 0.4450\n",
      "Epoch 40/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8139 - loss: 0.4296\n",
      "Epoch 40/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8197 - loss: 0.4204\n",
      "Epoch 40/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8057 - loss: 0.4347\n",
      "Epoch 38/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8082 - loss: 0.4436\n",
      "Epoch 41/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8105 - loss: 0.4451\n",
      "Epoch 41/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8110 - loss: 0.4252\n",
      "Epoch 41/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8118 - loss: 0.4319 \n",
      "Epoch 41/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8014 - loss: 0.4369\n",
      "Epoch 39/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8239 - loss: 0.4163\n",
      "Epoch 42/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8126 - loss: 0.4282\n",
      "Epoch 42/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8098 - loss: 0.4284\n",
      "Epoch 42/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.4332\n",
      "Epoch 42/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8119 - loss: 0.4251\n",
      "Epoch 40/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8122 - loss: 0.4370\n",
      "Epoch 43/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8162 - loss: 0.4322\n",
      "Epoch 43/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8124 - loss: 0.4266\n",
      "Epoch 43/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8151 - loss: 0.4255\n",
      "Epoch 43/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.4361\n",
      "Epoch 41/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8153 - loss: 0.4336\n",
      "Epoch 44/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.4392\n",
      "Epoch 44/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8096 - loss: 0.4384\n",
      "Epoch 44/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8059 - loss: 0.4420\n",
      "Epoch 44/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8045 - loss: 0.4397\n",
      "Epoch 45/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8151 - loss: 0.4209\n",
      "Epoch 42/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8129 - loss: 0.4398\n",
      "Epoch 45/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8125 - loss: 0.4313\n",
      "Epoch 45/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8126 - loss: 0.4336\n",
      "Epoch 45/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8122 - loss: 0.4338\n",
      "Epoch 46/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8040 - loss: 0.4340\n",
      "Epoch 43/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.4326\n",
      "Epoch 46/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8109 - loss: 0.4372\n",
      "Epoch 46/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8039 - loss: 0.4313\n",
      "Epoch 46/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8070 - loss: 0.4342\n",
      "Epoch 47/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8028 - loss: 0.4422\n",
      "Epoch 44/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.4347\n",
      "Epoch 47/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8127 - loss: 0.4174\n",
      "Epoch 47/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8110 - loss: 0.4268\n",
      "Epoch 47/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8116 - loss: 0.4332\n",
      "Epoch 48/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8060 - loss: 0.4263\n",
      "Epoch 45/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: 0.4444\n",
      "Epoch 48/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.4167\n",
      "Epoch 48/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8176 - loss: 0.4243\n",
      "Epoch 48/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8118 - loss: 0.4377\n",
      "Epoch 49/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8088 - loss: 0.4329\n",
      "Epoch 46/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8214 - loss: 0.4228\n",
      "Epoch 49/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8159 - loss: 0.4255\n",
      "Epoch 49/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8158 - loss: 0.4306\n",
      "\u001b[1m  1/167\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.7500 - loss: 0.5833Epoch 49/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8145 - loss: 0.4298\n",
      "Epoch 50/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8133 - loss: 0.4265\n",
      "Epoch 47/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8034 - loss: 0.4474\n",
      "Epoch 50/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8087 - loss: 0.4391\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8117 - loss: 0.4273Epoch 50/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8117 - loss: 0.4274\n",
      "Epoch 50/50\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8100 - loss: 0.4380\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8112 - loss: 0.4253\n",
      "Epoch 48/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8145 - loss: 0.4309\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8057 - loss: 0.4351\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.4288\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8115 - loss: 0.4260\n",
      "Epoch 49/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepuracy: 0.8438 - loss: 0.30\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepep - accuracy: 0.8399 - loss: 0.377\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8215 - loss: 0.4108\n",
      "Epoch 50/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.8083 - loss: 0.4276\n",
      "Epoch 51/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.8225 - loss: 0.4101\n",
      "Epoch 52/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.8093 - loss: 0.4287\n",
      "Epoch 53/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.8099 - loss: 0.4212\n",
      "Epoch 54/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.8155 - loss: 0.4139\n",
      "Epoch 55/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.8148 - loss: 0.4296\n",
      "Epoch 56/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.8070 - loss: 0.4277\n",
      "Epoch 57/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.8199 - loss: 0.4093\n",
      "Epoch 58/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.8089 - loss: 0.4343\n",
      "Epoch 59/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.8117 - loss: 0.4270\n",
      "Epoch 60/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.8020 - loss: 0.4352\n",
      "Epoch 61/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.8125 - loss: 0.4222\n",
      "Epoch 62/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.8129 - loss: 0.4206\n",
      "Epoch 63/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.8019 - loss: 0.4352\n",
      "Epoch 64/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.8144 - loss: 0.4251\n",
      "Epoch 65/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.8037 - loss: 0.4438\n",
      "Epoch 66/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.8066 - loss: 0.4317\n",
      "Epoch 67/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.8139 - loss: 0.4228\n",
      "Epoch 68/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.8201 - loss: 0.4194\n",
      "Epoch 69/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.8086 - loss: 0.4336\n",
      "Epoch 70/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.8028 - loss: 0.4449\n",
      "Epoch 71/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.8101 - loss: 0.4189\n",
      "Epoch 72/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.8137 - loss: 0.4247\n",
      "Epoch 73/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.8069 - loss: 0.4271\n",
      "Epoch 74/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.8054 - loss: 0.4284\n",
      "Epoch 75/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.8021 - loss: 0.4327\n",
      "Epoch 76/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.8017 - loss: 0.4374\n",
      "Epoch 77/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.8112 - loss: 0.4268\n",
      "Epoch 78/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.8112 - loss: 0.4288\n",
      "Epoch 79/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.8035 - loss: 0.4344\n",
      "Epoch 80/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.8183 - loss: 0.4191\n",
      "Epoch 81/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.8161 - loss: 0.4179\n",
      "Epoch 82/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.8051 - loss: 0.4327\n",
      "Epoch 83/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.8147 - loss: 0.4236\n",
      "Epoch 84/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.8134 - loss: 0.4262\n",
      "Epoch 85/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.8153 - loss: 0.4167\n",
      "Epoch 86/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.8168 - loss: 0.4165\n",
      "Epoch 87/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.8108 - loss: 0.4301\n",
      "Epoch 88/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8117 - loss: 0.4252  \n",
      "Epoch 89/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8172 - loss: 0.4249  \n",
      "Epoch 90/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8127 - loss: 0.4262\n",
      "Epoch 91/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 0.8133 - loss: 0.4216\n",
      "Epoch 92/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.8088 - loss: 0.4226\n",
      "Epoch 93/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.8064 - loss: 0.4271\n",
      "Epoch 94/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.8041 - loss: 0.4365\n",
      "Epoch 95/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.8050 - loss: 0.4292\n",
      "Epoch 96/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.8049 - loss: 0.4370\n",
      "Epoch 97/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 0.8019 - loss: 0.4455\n",
      "Epoch 98/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.8146 - loss: 0.4247\n",
      "Epoch 99/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.8096 - loss: 0.4317\n",
      "Epoch 100/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.8076 - loss: 0.4314\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:516: FitFailedWarning: \n",
      "43 fits failed out of a total of 48.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 925, in _fit\n",
      "    X, y = self._initialize(X, y)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 862, in _initialize\n",
      "    self.model_ = self._build_keras_model()\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 433, in _build_keras_model\n",
      "    model = final_build_fn(**build_params)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_27074/2568856508.py\", line 10, in create_model\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/models/sequential.py\", line 122, in add\n",
      "    self._maybe_rebuild()\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/models/sequential.py\", line 149, in _maybe_rebuild\n",
      "    self.build(input_shape)\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 232, in build_wrapper\n",
      "    original_build_method(*args, **kwargs)\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/models/sequential.py\", line 195, in build\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py\", line 151, in convert_to_tensor\n",
      "    x = tf.convert_to_tensor(x)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tensorflow.python.framework.errors_impl.InternalError: cudaSetDevice() on GPU:0 failed. Status: out of memory\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 938, in _fit\n",
      "    self._fit_keras_model(\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 535, in _fit_keras_model\n",
      "    hist = self.model_.fit(x=X, y=y, **fit_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    except TypeError as e:\n",
      "tensorflow.python.framework.errors_impl.FailedPreconditionError: Graph execution error:\n",
      "\n",
      "Detected at node StatefulPartitionedCall defined at (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 490, in _process_worker\n",
      "\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n",
      "\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 607, in __call__\n",
      "\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 147, in __call__\n",
      "\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 1501, in fit\n",
      "\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 770, in fit\n",
      "\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 938, in _fit\n",
      "\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 535, in _fit_keras_model\n",
      "\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n",
      "\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n",
      "\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n",
      "\n",
      "DNN library initialization failed. Look at the errors above for more details.\n",
      "\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_779]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 925, in _fit\n",
      "    X, y = self._initialize(X, y)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 862, in _initialize\n",
      "    self.model_ = self._build_keras_model()\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 433, in _build_keras_model\n",
      "    model = final_build_fn(**build_params)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_27074/2568856508.py\", line 8, in create_model\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/models/sequential.py\", line 122, in add\n",
      "    self._maybe_rebuild()\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/models/sequential.py\", line 149, in _maybe_rebuild\n",
      "    self.build(input_shape)\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 232, in build_wrapper\n",
      "    original_build_method(*args, **kwargs)\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/models/sequential.py\", line 195, in build\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py\", line 151, in convert_to_tensor\n",
      "    x = tf.convert_to_tensor(x)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tensorflow.python.framework.errors_impl.InternalError: cudaSetDevice() on GPU:0 failed. Status: out of memory\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 925, in _fit\n",
      "    X, y = self._initialize(X, y)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 862, in _initialize\n",
      "    self.model_ = self._build_keras_model()\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 433, in _build_keras_model\n",
      "    model = final_build_fn(**build_params)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_27074/2568856508.py\", line 8, in create_model\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/models/sequential.py\", line 122, in add\n",
      "    self._maybe_rebuild()\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/models/sequential.py\", line 149, in _maybe_rebuild\n",
      "    self.build(input_shape)\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 232, in build_wrapper\n",
      "    original_build_method(*args, **kwargs)\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/models/sequential.py\", line 195, in build\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py\", line 151, in convert_to_tensor\n",
      "    x = tf.convert_to_tensor(x)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tensorflow.python.framework.errors_impl.InternalError: cudaSetDevice() on GPU:0 failed. Status: CUDA-capable device(s) is/are busy or unavailable\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 1501, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 770, in fit\n",
      "    self._fit(\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 925, in _fit\n",
      "    X, y = self._initialize(X, y)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 862, in _initialize\n",
      "    self.model_ = self._build_keras_model()\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py\", line 433, in _build_keras_model\n",
      "    model = final_build_fn(**build_params)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_27074/2568856508.py\", line 10, in create_model\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/models/sequential.py\", line 122, in add\n",
      "    self._maybe_rebuild()\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/models/sequential.py\", line 149, in _maybe_rebuild\n",
      "    self.build(input_shape)\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 232, in build_wrapper\n",
      "    original_build_method(*args, **kwargs)\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/models/sequential.py\", line 195, in build\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py\", line 151, in convert_to_tensor\n",
      "    x = tf.convert_to_tensor(x)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tensorflow.python.framework.errors_impl.InternalError: cudaSetDevice() on GPU:0 failed. Status: CUDA-capable device(s) is/are busy or unavailable\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/home/vikramaditya/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "cudaSetDevice() on GPU:0 failed. Status: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Perform grid search\u001b[39;00m\n\u001b[32m      2\u001b[39m grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-\u001b[32m1\u001b[39m, cv=\u001b[32m3\u001b[39m,verbose=\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m grid_result = \u001b[43mgrid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Print the best parameters\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m using \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % (grid_result.best_score_, grid_result.best_params_))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1089\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1087\u001b[39m refit_start_time = time.time()\n\u001b[32m   1088\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbest_estimator_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1091\u001b[39m     \u001b[38;5;28mself\u001b[39m.best_estimator_.fit(X, **routed_params.estimator.fit)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:1501\u001b[39m, in \u001b[36mKerasClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, **kwargs)\u001b[39m\n\u001b[32m   1499\u001b[39m     sample_weight = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight\n\u001b[32m   1500\u001b[39m     sample_weight *= compute_sample_weight(class_weight=\u001b[38;5;28mself\u001b[39m.class_weight, y=y)\n\u001b[32m-> \u001b[39m\u001b[32m1501\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:770\u001b[39m, in \u001b[36mBaseWrapper.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, **kwargs)\u001b[39m\n\u001b[32m    765\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m\"\u001b[39m] = kwargs.get(\n\u001b[32m    766\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfit__epochs\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.epochs)\n\u001b[32m    767\u001b[39m )\n\u001b[32m    768\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33minitial_epoch\u001b[39m\u001b[33m\"\u001b[39m] = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33minitial_epoch\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    772\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    773\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:925\u001b[39m, in \u001b[36mBaseWrapper._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[39m\n\u001b[32m    923\u001b[39m \u001b[38;5;66;03m# Data checks\u001b[39;00m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ((\u001b[38;5;28mself\u001b[39m.warm_start \u001b[38;5;129;01mor\u001b[39;00m warm_start) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.initialized_):\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     X, y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    927\u001b[39m     X, y = \u001b[38;5;28mself\u001b[39m._validate_data(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:862\u001b[39m, in \u001b[36mBaseWrapper._initialize\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    859\u001b[39m feature_meta = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.feature_encoder, \u001b[33m\"\u001b[39m\u001b[33mget_metadata\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mdict\u001b[39m)()\n\u001b[32m    860\u001b[39m \u001b[38;5;28mvars\u001b[39m(\u001b[38;5;28mself\u001b[39m).update(**feature_meta)\n\u001b[32m--> \u001b[39m\u001b[32m862\u001b[39m \u001b[38;5;28mself\u001b[39m.model_ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_keras_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[38;5;28mself\u001b[39m._initialize_callbacks()\n\u001b[32m    865\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/scikeras/wrappers.py:433\u001b[39m, in \u001b[36mBaseWrapper._build_keras_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    431\u001b[39m         model = final_build_fn(**build_params)\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m     model = \u001b[43mfinal_build_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbuild_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mcreate_model\u001b[39m\u001b[34m(neurons, layers)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(layers-\u001b[32m1\u001b[39m):\n\u001b[32m      8\u001b[39m     model.add(Dense(neurons,activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msigmoid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m model.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m,loss=\u001b[33m\"\u001b[39m\u001b[33mbinary_crossentropy\u001b[39m\u001b[33m\"\u001b[39m,metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/models/sequential.py:122\u001b[39m, in \u001b[36mSequential.add\u001b[39m\u001b[34m(self, layer, rebuild)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28mself\u001b[39m._layers.append(layer)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rebuild:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28mself\u001b[39m.built = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/models/sequential.py:149\u001b[39m, in \u001b[36mSequential._maybe_rebuild\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers) > \u001b[32m1\u001b[39m:\n\u001b[32m    148\u001b[39m     input_shape = \u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m].batch_shape\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33minput_shape\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers) > \u001b[32m1\u001b[39m:\n\u001b[32m    151\u001b[39m     \u001b[38;5;66;03m# We can build the Sequential model if the first layer has the\u001b[39;00m\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# `input_shape` property. This is most commonly found in Functional\u001b[39;00m\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# model.\u001b[39;00m\n\u001b[32m    154\u001b[39m     input_shape = \u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m].input_shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py:232\u001b[39m, in \u001b[36mLayer.__new__.<locals>.build_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m obj._open_name_scope():\n\u001b[32m    231\u001b[39m     obj._path = current_path()\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[32m    234\u001b[39m signature = inspect.signature(original_build_method)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/models/sequential.py:195\u001b[39m, in \u001b[36mSequential.build\u001b[39m\u001b[34m(self, input_shape)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._layers[\u001b[32m1\u001b[39m:]:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m         x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m    197\u001b[39m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[32m    198\u001b[39m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[32m    199\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/ChurnClassificationANN/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:151\u001b[39m, in \u001b[36mconvert_to_tensor\u001b[39m\u001b[34m(x, dtype, sparse, ragged)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf.is_tensor(x):\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype == \u001b[33m\"\u001b[39m\u001b[33mbool\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_int_dtype(dtype):\n\u001b[32m    148\u001b[39m         \u001b[38;5;66;03m# TensorFlow conversion is stricter than other backends, it does not\u001b[39;00m\n\u001b[32m    149\u001b[39m         \u001b[38;5;66;03m# allow ints for bools or floats for ints. We convert without dtype\u001b[39;00m\n\u001b[32m    150\u001b[39m         \u001b[38;5;66;03m# and cast instead.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m         x = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tf.cast(x, dtype)\n\u001b[32m    153\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tf.convert_to_tensor(x, dtype=dtype)\n",
      "\u001b[31mInternalError\u001b[39m: cudaSetDevice() on GPU:0 failed. Status: out of memory"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3,verbose=1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c70e52-ae89-4b4c-a05e-6d4506d5a5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ChurnANN-env)",
   "language": "python",
   "name": "churnann-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
